# L# Data Engineer Technical Assignment â€“ Lemici IQ

This repository contains my solution for the **Lemici IQ â€“ Data Engineer Technical Assignment**.  
The project focuses on exploratory data analysis, machine learning fundamentals, and the design of a safe and explainable Retrieval-Augmented Generation (RAG) system for customer support use cases.

---

## ğŸ“‚ Project Structure

â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â”‚ â””â”€â”€ customer_support_tickets.csv
â”‚ â””â”€â”€ processed/
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ EDA_Customer_Satisfaction.ipynb
â”‚ â””â”€â”€ Part_2_ML.ipynb
â”‚ â””â”€â”€ Part_3_ML.ipynb
â”‚
â”œâ”€â”€ rag/
â”‚ â”œâ”€â”€ data_loader.py
â”‚ â”œâ”€â”€ embeddings.py
â”‚ â”œâ”€â”€ vector_store.py
â”‚ â”œâ”€â”€ retriever.py
â”‚ â”œâ”€â”€ prompt.py
â”‚ â”œâ”€â”€ generator.py
â”‚ â””â”€â”€ pipeline.py
â”‚
â”œâ”€â”€ RAG_DESIGN.md
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ test_*.py


---

## ğŸ§ª Part 1: Exploratory Data Analysis (EDA)

- Performed data quality checks (missing values, duplicates, anomalies)
- Analyzed resolution times across ticket categories and priorities
- Conducted text analysis on customer messages
- Explored relationships between features and customer satisfaction
- Documented insights and critical thinking directly in the notebook

ğŸ“ **Notebook**: `EDA_Customer_Satisfaction.ipynb`

---

## ğŸ¤– Part 2: Machine Learning Fundamentals

- Built a multi-class classifier to predict ticket priority
- Implemented and compared multiple models (e.g., Logistic Regression, Tree-based models)
- Applied text feature engineering techniques
- Evaluated models using appropriate metrics (accuracy, precision, recall, F1, confusion matrix)
- Performed hyperparameter tuning with justification
- Discussed business impact and model limitations

ğŸ“ **Notebook**: `Part_2_ML.ipynb`

---

## ğŸ§  Part 3: LLM & RAG System

This project includes a **Retrieval-Augmented Generation (RAG)** system that suggests customer support responses based on historical agent replies.

### ğŸ”‘ Key Design Choices
- Each historical agent response is treated as a **single semantic unit** (no chunking)
- SentenceTransformer (`all-MiniLM-L6-v2`) used for embedding generation
- FAISS used as a local vector database for similarity search
- Similarity score threshold applied to filter weak or noisy matches
- Safe prompt engineering to discourage hallucinations
- Fallback logic for queries with no relevant historical context

### ğŸ—ï¸ RAG Pipeline Flow

User Query
â†“
Query Embedding
â†“
Vector Similarity Search (FAISS)
â†“
Filtered Context Retrieval
â†“
Prompt Construction
â†“
LLM Response Generation


### â–¶ï¸ How to Run the RAG Pipeline

1. Install dependencies:
```bash
pip install -r requirements.txt

python test_pipeline.py

python evaluate_rag.py

### How to Run
```bash
pip install -r requirements.txt
python test_pipeline.

NOTE

A mock LLM generator is used to focus on RAG architecture, retrieval quality, and safety mechanisms.
This component can be easily replaced with an API-based or local open-source LLM without modifying the pipeline design.

Evaluation

Implemented basic retrieval evaluation metrics

Measured retrieval hit rate across representative test queries

Prioritized precision and safety over recall due to noisy historical data

Designed system to avoid hallucinations when confidence is low


Design Philosophy

Emphasis on explainability and safety

Conservative retrieval to prevent incorrect suggestions

Modular, testable, and extensible architecture

Practical handling of real-world data limitations

Future Improvements

Integrate a real LLM (OpenAI / Mistral / Llama)

Add re-ranking using cross-encoders

Improve knowledge base quality with ticketâ€“response pairing

Add unit tests for critical RAG components

Expose the pipeline via a lightweight API (FastAPI)

Notes

This assignment prioritizes design reasoning and understanding over heavy frameworks

All major design decisions are documented in RAG_DESIGN.md

The solution is intentionally conservative to ensure correctness and trustworthiness


